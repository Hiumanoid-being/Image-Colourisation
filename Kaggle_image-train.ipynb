{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114f5907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T05:28:04.759531Z",
     "iopub.status.busy": "2025-11-22T05:28:04.759016Z",
     "iopub.status.idle": "2025-11-22T05:28:04.762487Z",
     "shell.execute_reply": "2025-11-22T05:28:04.762024Z"
    },
    "papermill": {
     "duration": 0.008019,
     "end_time": "2025-11-22T05:28:04.763501",
     "exception": false,
     "start_time": "2025-11-22T05:28:04.755482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "#path = kagglehub.dataset_download(\"chanyoongqiedison/training\")\n",
    "\n",
    "#print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d1c1179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T05:28:04.768532Z",
     "iopub.status.busy": "2025-11-22T05:28:04.768339Z",
     "iopub.status.idle": "2025-11-22T05:28:11.077864Z",
     "shell.execute_reply": "2025-11-22T05:28:11.077289Z"
    },
    "papermill": {
     "duration": 6.313672,
     "end_time": "2025-11-22T05:28:11.079344",
     "exception": false,
     "start_time": "2025-11-22T05:28:04.765672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cnn_transformer_colorizer_v1.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=1, feature_dim=256):\n",
    "        super().__init__()\n",
    "        # Store intermediate features for skip connections\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, feature_dim, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(feature_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)  # [B, 64, H, W]\n",
    "        x2 = self.conv2(x1) # [B, 128, H/2, W/2]\n",
    "        x3 = self.conv3(x2) # [B, 256, H/4, W/4]\n",
    "        x4 = self.conv4(x3) # [B, 256, H/4, W/4]\n",
    "        return x4, (x1, x2, x3)  # Return features for skip connections\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, feature_dim=256, num_heads=8, num_layers=4, patch_size=4):\n",
    "        super().__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        # Calculate projection dimension (patch_size^2 * feature_dim)\n",
    "        patch_dim = patch_size * patch_size * feature_dim\n",
    "        \n",
    "        # Create projection layer as a module (will be trained)\n",
    "        self.patch_projection = nn.Linear(patch_dim, feature_dim)\n",
    "        \n",
    "        # Positional embedding (will be adjusted dynamically if needed)\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, 256, feature_dim))\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=feature_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=feature_dim * 4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        # Split feature map into patches\n",
    "        x = x.unfold(2, self.patch_size, self.patch_size)\\\n",
    "             .unfold(3, self.patch_size, self.patch_size)\n",
    "        x = x.contiguous().view(B, C, -1, self.patch_size * self.patch_size)\n",
    "        x = x.permute(0, 2, 1, 3).flatten(2)  # [B, N_patches, C * patch_area]\n",
    "\n",
    "        # Project patches to feature dimension\n",
    "        x = self.patch_projection(x)  # [B, N_patches, feature_dim]\n",
    "        \n",
    "        # Add positional embedding\n",
    "        num_patches = x.size(1)\n",
    "        if num_patches <= self.pos_embed.size(1):\n",
    "            pos_emb = self.pos_embed[:, :num_patches, :]\n",
    "        else:\n",
    "            # Interpolate if we have more patches than expected\n",
    "            pos_emb = F.interpolate(\n",
    "                self.pos_embed.permute(0, 2, 1),\n",
    "                size=num_patches,\n",
    "                mode='linear',\n",
    "                align_corners=False\n",
    "            ).permute(0, 2, 1)\n",
    "        \n",
    "        x = x + pos_emb\n",
    "\n",
    "        # Transformer processing\n",
    "        x = self.transformer(x)\n",
    "        return x, (H, W)  # Return original spatial dims\n",
    "\n",
    "\n",
    "class ColorDecoder(nn.Module):\n",
    "    def __init__(self, feature_dim=256):\n",
    "        super().__init__()\n",
    "        # Enhanced decoder with more capacity and skip connections\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(feature_dim, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256 + 256, 128, 4, stride=2, padding=1),  # + skip from encoder\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.up3 = nn.Sequential(\n",
    "            nn.Conv2d(128 + 128, 128, 3, stride=1, padding=1),  # + skip from encoder\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(128 + 64, 64, 3, stride=1, padding=1),  # + skip from encoder\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 2, 3, stride=1, padding=1),\n",
    "            nn.Tanh()  # final a,b in [-1,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, orig_H, orig_W, skip_features=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [B, N_patches, feature_dim]\n",
    "            orig_H, orig_W: Original input image dimensions\n",
    "            skip_features: Tuple of (x1, x2, x3) from encoder\n",
    "        \"\"\"\n",
    "        B, N, C = x.shape\n",
    "        side = int(N ** 0.5)\n",
    "        \n",
    "        # Reshape patches back to spatial grid\n",
    "        x = x.permute(0, 2, 1).view(B, C, side, side)  # [B, feature_dim, H', W']\n",
    "\n",
    "        # Apply decoder upsampling with skip connections\n",
    "        x = self.up1(x)  # 2x upsampling\n",
    "        \n",
    "        if skip_features is not None:\n",
    "            # Add skip connection from encoder's conv3 (after proper sizing)\n",
    "            skip3 = skip_features[2]  # [B, 256, H/4, W/4]\n",
    "            if skip3.shape[2:] != x.shape[2:]:\n",
    "                skip3 = F.interpolate(skip3, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "            x = torch.cat([x, skip3], dim=1)\n",
    "        \n",
    "        x = self.up2(x)  # 4x upsampling total\n",
    "        \n",
    "        if skip_features is not None:\n",
    "            # Add skip connection from encoder's conv2\n",
    "            skip2 = skip_features[1]  # [B, 128, H/2, W/2]\n",
    "            if skip2.shape[2:] != x.shape[2:]:\n",
    "                skip2 = F.interpolate(skip2, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "            x = torch.cat([x, skip2], dim=1)\n",
    "        \n",
    "        x = self.up3(x)\n",
    "        \n",
    "        if skip_features is not None:\n",
    "            # Add skip connection from encoder's conv1\n",
    "            skip1 = skip_features[0]  # [B, 64, H, W]\n",
    "            if skip1.shape[2:] != x.shape[2:]:\n",
    "                skip1 = F.interpolate(skip1, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "            x = torch.cat([x, skip1], dim=1)\n",
    "        \n",
    "        x = self.final(x)\n",
    "        \n",
    "        # Final resize to exact target dimensions\n",
    "        if x.shape[2] != orig_H or x.shape[3] != orig_W:\n",
    "            x = F.interpolate(x, size=(orig_H, orig_W), mode=\"bilinear\", align_corners=False)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNTransformerColorizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = CNNEncoder()\n",
    "        self.transformer = TransformerEncoder()\n",
    "        self.decoder = ColorDecoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        orig_H, orig_W = x.shape[2], x.shape[3]\n",
    "        \n",
    "        # Encode with skip connections\n",
    "        feat, skip_features = self.encoder(x)  # [B, 256, H/4, W/4]\n",
    "        \n",
    "        # Transform\n",
    "        trans, (enc_H, enc_W) = self.transformer(feat)  # [B, N_patches, 256]\n",
    "        \n",
    "        # Decode with skip connections\n",
    "        ab = self.decoder(trans, orig_H, orig_W, skip_features)  # [B, 2, H, W]\n",
    "        \n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da244e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T05:28:11.085587Z",
     "iopub.status.busy": "2025-11-22T05:28:11.085296Z",
     "iopub.status.idle": "2025-11-22T10:51:59.326509Z",
     "shell.execute_reply": "2025-11-22T10:51:59.325635Z"
    },
    "papermill": {
     "duration": 19428.24619,
     "end_time": "2025-11-22T10:51:59.327789",
     "exception": false,
     "start_time": "2025-11-22T05:28:11.081599",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 GPU(s)\n",
      "  - GPU 0: Tesla T4\n",
      "    Memory: 14.7 GB\n",
      "  - GPU 1: Tesla T4\n",
      "    Memory: 14.7 GB\n",
      "Using 2 GPUs with DataParallel\n",
      "Available datasets: ['processed']\n",
      "Using fallback dataset: /kaggle/input/100k-data/processed\n",
      "Using data directory: /kaggle/input/100k-data/processed\n",
      "ðŸ“ Loading TRAIN split\n",
      "Searching for grayscale images in: /kaggle/input/100k-data/processed/grayscale/train\n",
      "ðŸ“ Total grayscale images found: 10000\n",
      "Training with 10000 images\n",
      "Batch size: 16 (adjusted for 2 GPU(s))\n",
      "Starting training with enhanced colorization...\n",
      "Checkpoints and visualizations will be saved every 20 epochs\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   0%|          | 0/625 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sanity check for shapes ===\n",
      "Input L shape: torch.Size([16, 1, 256, 256])\n",
      "Output (predicted AB) shape: torch.Size([16, 2, 256, 256])\n",
      "Target AB shape: torch.Size([16, 2, 256, 256])\n",
      "Output min/max: -0.7445 / 0.9611\n",
      "Target min/max: -0.7138 / 0.7822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   0%|          | 2/625 [00:04<19:23,  1.87s/it, loss=6.01e+3, l1=0.376, color=2e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Usage:\n",
      "  GPU 0: 0.15GB / 1.24GB\n",
      "  GPU 1: 0.01GB / 1.49GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:58<00:00,  5.29it/s, loss=4.2e+3, l1=0.105, color=1.4e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200] - Loss: 4279.051053 (L1: 0.086391, Color: 14263.270075, Sat: -0.082702)\n",
      "Learning Rate: 1.00e-03\n",
      "\n",
      "ðŸ’¾ Checkpoint at epoch 1\n",
      "âœ… Checkpoint saved: /kaggle/working/checkpoint_epoch_001.pth\n",
      "ðŸŽ¨ Generating visualization...\n",
      "âœ… Visualization saved: /kaggle/working/visualization_epoch_001.png\n",
      "ðŸ“Š Loss plot saved\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:43<00:00,  6.04it/s, loss=5.32e+3, l1=0.116, color=1.77e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200] - Loss: 4643.313466 (L1: 0.079551, Color: 15477.495775, Sat: -0.075054)\n",
      "Learning Rate: 9.99e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:42<00:00,  6.08it/s, loss=5.22e+3, l1=0.108, color=1.74e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200] - Loss: 4554.907971 (L1: 0.079117, Color: 15182.817100, Sat: -0.082290)\n",
      "Learning Rate: 9.98e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:41<00:00,  6.16it/s, loss=5.2e+3, l1=0.0976, color=1.73e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200] - Loss: 4573.524333 (L1: 0.078860, Color: 15244.872750, Sat: -0.082762)\n",
      "Learning Rate: 9.96e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:40<00:00,  6.22it/s, loss=4.92e+3, l1=0.0938, color=1.64e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200] - Loss: 4610.094829 (L1: 0.078599, Color: 15366.776600, Sat: -0.084645)\n",
      "Learning Rate: 9.94e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:39<00:00,  6.29it/s, loss=4.13e+3, l1=0.0629, color=1.38e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200] - Loss: 4601.235874 (L1: 0.078328, Color: 15337.247900, Sat: -0.085069)\n",
      "Learning Rate: 9.91e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:38<00:00,  6.32it/s, loss=3.81e+3, l1=0.0669, color=1.27e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/200] - Loss: 4561.533809 (L1: 0.078015, Color: 15204.909075, Sat: -0.085599)\n",
      "Learning Rate: 9.88e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.39it/s, loss=4.77e+3, l1=0.0844, color=1.59e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200] - Loss: 4540.697059 (L1: 0.078050, Color: 15135.453375, Sat: -0.085958)\n",
      "Learning Rate: 9.84e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.41it/s, loss=4.52e+3, l1=0.0841, color=1.51e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/200] - Loss: 4539.378521 (L1: 0.077924, Color: 15131.058975, Sat: -0.086389)\n",
      "Learning Rate: 9.80e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.41it/s, loss=4.59e+3, l1=0.0637, color=1.53e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200] - Loss: 4523.889778 (L1: 0.077812, Color: 15079.430400, Sat: -0.086627)\n",
      "Learning Rate: 9.76e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.38it/s, loss=4.36e+3, l1=0.0594, color=1.45e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200] - Loss: 4509.896091 (L1: 0.077771, Color: 15032.784700, Sat: -0.086403)\n",
      "Learning Rate: 9.70e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.38it/s, loss=5.17e+3, l1=0.0756, color=1.72e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/200] - Loss: 4536.452355 (L1: 0.077753, Color: 15121.305950, Sat: -0.086793)\n",
      "Learning Rate: 9.65e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.42it/s, loss=4.17e+3, l1=0.0747, color=1.39e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/200] - Loss: 4476.235255 (L1: 0.077671, Color: 14920.582650, Sat: -0.086969)\n",
      "Learning Rate: 9.59e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.44it/s, loss=4.57e+3, l1=0.0857, color=1.52e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/200] - Loss: 4478.461896 (L1: 0.077638, Color: 14928.004775, Sat: -0.086763)\n",
      "Learning Rate: 9.52e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.42it/s, loss=4.9e+3, l1=0.0852, color=1.63e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/200] - Loss: 4421.368959 (L1: 0.077479, Color: 14737.695400, Sat: -0.086652)\n",
      "Learning Rate: 9.46e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.43it/s, loss=4.09e+3, l1=0.0759, color=1.36e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/200] - Loss: 4460.804539 (L1: 0.077569, Color: 14869.147200, Sat: -0.086831)\n",
      "Learning Rate: 9.38e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.44it/s, loss=5.01e+3, l1=0.0792, color=1.67e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/200] - Loss: 4442.883009 (L1: 0.077400, Color: 14809.409675, Sat: -0.087334)\n",
      "Learning Rate: 9.30e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.44it/s, loss=4.69e+3, l1=0.0551, color=1.56e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/200] - Loss: 4416.575976 (L1: 0.077420, Color: 14721.719275, Sat: -0.087029)\n",
      "Learning Rate: 9.22e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.42it/s, loss=5.06e+3, l1=0.102, color=1.69e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/200] - Loss: 4402.512464 (L1: 0.077396, Color: 14674.841200, Sat: -0.087260)\n",
      "Learning Rate: 9.14e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=3.71e+3, l1=0.0732, color=1.24e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200] - Loss: 4404.977488 (L1: 0.077291, Color: 14683.058150, Sat: -0.087223)\n",
      "Learning Rate: 9.05e-04\n",
      "\n",
      "ðŸ’¾ Checkpoint at epoch 20\n",
      "âœ… Checkpoint saved: /kaggle/working/checkpoint_epoch_020.pth\n",
      "ðŸŽ¨ Generating visualization...\n",
      "âœ… Visualization saved: /kaggle/working/visualization_epoch_020.png\n",
      "ðŸ“Š Loss plot saved\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.22e+3, l1=0.0796, color=1.41e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/200] - Loss: 4364.239666 (L1: 0.077414, Color: 14547.265200, Sat: -0.087437)\n",
      "Learning Rate: 8.95e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.32e+3, l1=0.0885, color=1.44e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/200] - Loss: 4375.919800 (L1: 0.077383, Color: 14586.199250, Sat: -0.087672)\n",
      "Learning Rate: 8.85e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.81e+3, l1=0.0906, color=1.6e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/200] - Loss: 4361.923671 (L1: 0.077181, Color: 14539.546250, Sat: -0.087816)\n",
      "Learning Rate: 8.75e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=4.82e+3, l1=0.0649, color=1.61e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/200] - Loss: 4320.464080 (L1: 0.077195, Color: 14401.347550, Sat: -0.087798)\n",
      "Learning Rate: 8.65e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=3.58e+3, l1=0.0681, color=1.19e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/200] - Loss: 4333.708584 (L1: 0.077164, Color: 14445.495950, Sat: -0.087671)\n",
      "Learning Rate: 8.54e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.29e+3, l1=0.0778, color=1.43e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/200] - Loss: 4339.843327 (L1: 0.077049, Color: 14465.945475, Sat: -0.087765)\n",
      "Learning Rate: 8.42e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.38e+3, l1=0.0932, color=1.46e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/200] - Loss: 4306.778883 (L1: 0.077130, Color: 14355.730525, Sat: -0.087952)\n",
      "Learning Rate: 8.31e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.35e+3, l1=0.0756, color=1.45e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/200] - Loss: 4300.455825 (L1: 0.076995, Color: 14334.654000, Sat: -0.087786)\n",
      "Learning Rate: 8.19e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=4.36e+3, l1=0.072, color=1.45e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/200] - Loss: 4309.478189 (L1: 0.077036, Color: 14364.728625, Sat: -0.088090)\n",
      "Learning Rate: 8.07e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=5.35e+3, l1=0.0903, color=1.78e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/200] - Loss: 4318.255700 (L1: 0.077092, Color: 14393.986675, Sat: -0.087907)\n",
      "Learning Rate: 7.94e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.77e+3, l1=0.0939, color=1.59e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/200] - Loss: 4288.690536 (L1: 0.076962, Color: 14295.436675, Sat: -0.088000)\n",
      "Learning Rate: 7.81e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=3.38e+3, l1=0.0639, color=1.13e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/200] - Loss: 4274.139464 (L1: 0.077018, Color: 14246.932950, Sat: -0.088079)\n",
      "Learning Rate: 7.68e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=4.57e+3, l1=0.0808, color=1.52e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/200] - Loss: 4259.190655 (L1: 0.077027, Color: 14197.103600, Sat: -0.088134)\n",
      "Learning Rate: 7.55e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.49it/s, loss=4.81e+3, l1=0.0836, color=1.6e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/200] - Loss: 4291.268861 (L1: 0.076980, Color: 14304.031100, Sat: -0.088120)\n",
      "Learning Rate: 7.41e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=4.6e+3, l1=0.0764, color=1.53e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/200] - Loss: 4283.602575 (L1: 0.076962, Color: 14278.477150, Sat: -0.088524)\n",
      "Learning Rate: 7.27e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=4.58e+3, l1=0.0769, color=1.53e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/200] - Loss: 4282.102202 (L1: 0.076805, Color: 14273.476200, Sat: -0.088152)\n",
      "Learning Rate: 7.13e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.50it/s, loss=4.47e+3, l1=0.0781, color=1.49e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/200] - Loss: 4236.359386 (L1: 0.076854, Color: 14121.000025, Sat: -0.088269)\n",
      "Learning Rate: 6.99e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.49it/s, loss=4.76e+3, l1=0.0916, color=1.59e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/200] - Loss: 4262.645979 (L1: 0.076827, Color: 14208.622175, Sat: -0.088376)\n",
      "Learning Rate: 6.84e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.49it/s, loss=4.58e+3, l1=0.0748, color=1.53e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/200] - Loss: 4228.677112 (L1: 0.076718, Color: 14095.392900, Sat: -0.088313)\n",
      "Learning Rate: 6.70e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.49it/s, loss=4.37e+3, l1=0.0667, color=1.46e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/200] - Loss: 4214.192985 (L1: 0.076723, Color: 14047.112325, Sat: -0.088042)\n",
      "Learning Rate: 6.55e-04\n",
      "\n",
      "ðŸ’¾ Checkpoint at epoch 40\n",
      "âœ… Checkpoint saved: /kaggle/working/checkpoint_epoch_040.pth\n",
      "ðŸŽ¨ Generating visualization...\n",
      "âœ… Visualization saved: /kaggle/working/visualization_epoch_040.png\n",
      "ðŸ“Š Loss plot saved\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.49e+3, l1=0.0757, color=1.5e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/200] - Loss: 4227.900159 (L1: 0.076706, Color: 14092.803225, Sat: -0.088459)\n",
      "Learning Rate: 6.40e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.51it/s, loss=3.52e+3, l1=0.0624, color=1.17e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/200] - Loss: 4225.626934 (L1: 0.076751, Color: 14085.225700, Sat: -0.088503)\n",
      "Learning Rate: 6.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=3.41e+3, l1=0.0654, color=1.14e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/200] - Loss: 4240.606240 (L1: 0.076678, Color: 14135.156975, Sat: -0.088543)\n",
      "Learning Rate: 6.09e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=3.57e+3, l1=0.071, color=1.19e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/200] - Loss: 4209.202559 (L1: 0.076594, Color: 14030.478225, Sat: -0.088411)\n",
      "Learning Rate: 5.94e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.49it/s, loss=3.94e+3, l1=0.0624, color=1.31e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/200] - Loss: 4224.902942 (L1: 0.076598, Color: 14082.812975, Sat: -0.088689)\n",
      "Learning Rate: 5.79e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.51it/s, loss=3.85e+3, l1=0.0722, color=1.28e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/200] - Loss: 4215.538341 (L1: 0.076672, Color: 14051.597250, Sat: -0.088433)\n",
      "Learning Rate: 5.63e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.49it/s, loss=4.83e+3, l1=0.0863, color=1.61e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/200] - Loss: 4189.203173 (L1: 0.076609, Color: 13963.813600, Sat: -0.088410)\n",
      "Learning Rate: 5.48e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=4.56e+3, l1=0.0871, color=1.52e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/200] - Loss: 4222.798648 (L1: 0.076639, Color: 14075.798725, Sat: -0.088862)\n",
      "Learning Rate: 5.32e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=3.94e+3, l1=0.0727, color=1.31e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/200] - Loss: 4182.173400 (L1: 0.076479, Color: 13940.381500, Sat: -0.088563)\n",
      "Learning Rate: 5.16e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=4.49e+3, l1=0.0766, color=1.5e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/200] - Loss: 4170.244210 (L1: 0.076445, Color: 13900.617900, Sat: -0.088845)\n",
      "Learning Rate: 5.01e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 51/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=4.56e+3, l1=0.0882, color=1.52e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/200] - Loss: 4174.241341 (L1: 0.076595, Color: 13913.941400, Sat: -0.089252)\n",
      "Learning Rate: 4.85e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 52/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=3.81e+3, l1=0.067, color=1.27e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/200] - Loss: 4147.025004 (L1: 0.076402, Color: 13823.220575, Sat: -0.088637)\n",
      "Learning Rate: 4.69e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 53/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.55it/s, loss=3.84e+3, l1=0.103, color=1.28e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/200] - Loss: 4159.836245 (L1: 0.076471, Color: 13865.924700, Sat: -0.089038)\n",
      "Learning Rate: 4.53e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=4.79e+3, l1=0.0828, color=1.6e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/200] - Loss: 4172.946147 (L1: 0.076383, Color: 13909.624325, Sat: -0.088516)\n",
      "Learning Rate: 4.38e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=3.92e+3, l1=0.0672, color=1.31e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/200] - Loss: 4163.893327 (L1: 0.076403, Color: 13879.448600, Sat: -0.089131)\n",
      "Learning Rate: 4.22e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 56/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.54it/s, loss=4.78e+3, l1=0.0879, color=1.59e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/200] - Loss: 4149.330558 (L1: 0.076340, Color: 13830.906200, Sat: -0.089008)\n",
      "Learning Rate: 4.07e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 57/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.49it/s, loss=3.78e+3, l1=0.0691, color=1.26e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/200] - Loss: 4122.927505 (L1: 0.076325, Color: 13742.896325, Sat: -0.089515)\n",
      "Learning Rate: 3.92e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=4.22e+3, l1=0.0692, color=1.41e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/200] - Loss: 4140.979095 (L1: 0.076201, Color: 13803.068150, Sat: -0.088612)\n",
      "Learning Rate: 3.76e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 59/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.54it/s, loss=4.23e+3, l1=0.0772, color=1.41e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/200] - Loss: 4127.688854 (L1: 0.076313, Color: 13758.767375, Sat: -0.089268)\n",
      "Learning Rate: 3.61e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=3.92e+3, l1=0.0667, color=1.31e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/200] - Loss: 4133.414299 (L1: 0.076275, Color: 13777.852400, Sat: -0.089321)\n",
      "Learning Rate: 3.46e-04\n",
      "\n",
      "ðŸ’¾ Checkpoint at epoch 60\n",
      "âœ… Checkpoint saved: /kaggle/working/checkpoint_epoch_060.pth\n",
      "ðŸŽ¨ Generating visualization...\n",
      "âœ… Visualization saved: /kaggle/working/visualization_epoch_060.png\n",
      "ðŸ“Š Loss plot saved\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.54it/s, loss=4.44e+3, l1=0.0854, color=1.48e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/200] - Loss: 4109.804812 (L1: 0.076215, Color: 13699.154250, Sat: -0.089242)\n",
      "Learning Rate: 3.31e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 62/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=4.31e+3, l1=0.08, color=1.44e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/200] - Loss: 4143.608060 (L1: 0.076230, Color: 13811.831575, Sat: -0.089129)\n",
      "Learning Rate: 3.17e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 63/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=4.51e+3, l1=0.0645, color=1.5e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/200] - Loss: 4108.338716 (L1: 0.076187, Color: 13694.267325, Sat: -0.089273)\n",
      "Learning Rate: 3.02e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 64/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=4.02e+3, l1=0.0799, color=1.34e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/200] - Loss: 4105.655179 (L1: 0.076156, Color: 13685.322450, Sat: -0.089369)\n",
      "Learning Rate: 2.88e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=3.74e+3, l1=0.0653, color=1.25e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/200] - Loss: 4112.643682 (L1: 0.076203, Color: 13708.617425, Sat: -0.089524)\n",
      "Learning Rate: 2.74e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 66/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=3.74e+3, l1=0.0691, color=1.25e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/200] - Loss: 4111.206188 (L1: 0.076134, Color: 13703.825775, Sat: -0.089269)\n",
      "Learning Rate: 2.60e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 67/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.49it/s, loss=4.35e+3, l1=0.0838, color=1.45e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/200] - Loss: 4077.262794 (L1: 0.076122, Color: 13590.681250, Sat: -0.089366)\n",
      "Learning Rate: 2.46e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 68/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.04e+3, l1=0.0769, color=1.35e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/200] - Loss: 4092.890504 (L1: 0.076041, Color: 13642.773900, Sat: -0.089374)\n",
      "Learning Rate: 2.33e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 69/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.51it/s, loss=3.67e+3, l1=0.0672, color=1.22e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/200] - Loss: 4072.647085 (L1: 0.076111, Color: 13575.295900, Sat: -0.089850)\n",
      "Learning Rate: 2.20e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=4.39e+3, l1=0.0787, color=1.46e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/200] - Loss: 4073.783343 (L1: 0.075971, Color: 13579.083425, Sat: -0.089135)\n",
      "Learning Rate: 2.07e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 71/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=4.09e+3, l1=0.0716, color=1.36e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/200] - Loss: 4073.543547 (L1: 0.075949, Color: 13578.284400, Sat: -0.089499)\n",
      "Learning Rate: 1.94e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 72/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.54it/s, loss=4.31e+3, l1=0.0918, color=1.44e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/200] - Loss: 4064.978859 (L1: 0.075955, Color: 13549.735450, Sat: -0.089528)\n",
      "Learning Rate: 1.82e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 73/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=4.13e+3, l1=0.0846, color=1.38e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/200] - Loss: 4056.181807 (L1: 0.075933, Color: 13520.411925, Sat: -0.089459)\n",
      "Learning Rate: 1.70e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=4e+3, l1=0.0791, color=1.33e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/200] - Loss: 4060.437573 (L1: 0.076040, Color: 13534.597825, Sat: -0.089905)\n",
      "Learning Rate: 1.59e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 75/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=3.84e+3, l1=0.068, color=1.28e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/200] - Loss: 4072.638574 (L1: 0.075974, Color: 13575.267875, Sat: -0.089691)\n",
      "Learning Rate: 1.47e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=4.19e+3, l1=0.0871, color=1.4e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/200] - Loss: 4061.076075 (L1: 0.075877, Color: 13536.726325, Sat: -0.089407)\n",
      "Learning Rate: 1.36e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 77/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=3.51e+3, l1=0.0719, color=1.17e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/200] - Loss: 4062.124281 (L1: 0.075839, Color: 13540.220500, Sat: -0.089392)\n",
      "Learning Rate: 1.26e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 78/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.49it/s, loss=4.28e+3, l1=0.0728, color=1.43e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/200] - Loss: 4043.618946 (L1: 0.075845, Color: 13478.536175, Sat: -0.089672)\n",
      "Learning Rate: 1.16e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 79/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.4e+3, l1=0.081, color=1.47e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/200] - Loss: 4051.050442 (L1: 0.075867, Color: 13503.307875, Sat: -0.089765)\n",
      "Learning Rate: 1.06e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.42e+3, l1=0.0816, color=1.47e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/200] - Loss: 4040.874711 (L1: 0.075837, Color: 13469.388875, Sat: -0.089788)\n",
      "Learning Rate: 9.64e-05\n",
      "\n",
      "ðŸ’¾ Checkpoint at epoch 80\n",
      "âœ… Checkpoint saved: /kaggle/working/checkpoint_epoch_080.pth\n",
      "ðŸŽ¨ Generating visualization...\n",
      "âœ… Visualization saved: /kaggle/working/visualization_epoch_080.png\n",
      "ðŸ“Š Loss plot saved\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.22e+3, l1=0.0739, color=1.41e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/200] - Loss: 4040.497114 (L1: 0.075820, Color: 13468.130225, Sat: -0.089702)\n",
      "Learning Rate: 8.74e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 82/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=3.73e+3, l1=0.0737, color=1.24e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/200] - Loss: 4035.209554 (L1: 0.075831, Color: 13450.505075, Sat: -0.089834)\n",
      "Learning Rate: 7.88e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.49it/s, loss=4.1e+3, l1=0.0776, color=1.37e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/200] - Loss: 4043.066651 (L1: 0.075702, Color: 13476.695525, Sat: -0.089390)\n",
      "Learning Rate: 7.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=3.72e+3, l1=0.0702, color=1.24e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/200] - Loss: 4027.527577 (L1: 0.075801, Color: 13424.898625, Sat: -0.089909)\n",
      "Learning Rate: 6.28e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 85/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.51it/s, loss=3.61e+3, l1=0.0739, color=1.2e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/200] - Loss: 4047.153757 (L1: 0.075749, Color: 13490.319275, Sat: -0.089746)\n",
      "Learning Rate: 5.54e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 86/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.50it/s, loss=3.38e+3, l1=0.0655, color=1.13e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/200] - Loss: 4029.683384 (L1: 0.075750, Color: 13432.084825, Sat: -0.089886)\n",
      "Learning Rate: 4.85e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 87/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=3.48e+3, l1=0.0581, color=1.16e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/200] - Loss: 4031.894077 (L1: 0.075714, Color: 13439.453800, Sat: -0.089725)\n",
      "Learning Rate: 4.21e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.44it/s, loss=3.77e+3, l1=0.0833, color=1.26e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/200] - Loss: 4022.242101 (L1: 0.075697, Color: 13407.280650, Sat: -0.089743)\n",
      "Learning Rate: 3.61e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.73e+3, l1=0.0926, color=1.58e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/200] - Loss: 4020.361195 (L1: 0.075644, Color: 13401.010950, Sat: -0.089550)\n",
      "Learning Rate: 3.05e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.05e+3, l1=0.093, color=1.35e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/200] - Loss: 4025.456220 (L1: 0.075722, Color: 13417.994450, Sat: -0.090007)\n",
      "Learning Rate: 2.54e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 91/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=3.8e+3, l1=0.07, color=1.27e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/200] - Loss: 4009.748584 (L1: 0.075631, Color: 13365.635675, Sat: -0.089627)\n",
      "Learning Rate: 2.08e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 92/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=4.17e+3, l1=0.071, color=1.39e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/200] - Loss: 4016.117142 (L1: 0.075610, Color: 13386.864250, Sat: -0.089566)\n",
      "Learning Rate: 1.67e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 93/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=3.9e+3, l1=0.0754, color=1.3e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/200] - Loss: 4025.440539 (L1: 0.075671, Color: 13417.942275, Sat: -0.089922)\n",
      "Learning Rate: 1.30e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.09e+3, l1=0.0755, color=1.36e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/200] - Loss: 4010.819583 (L1: 0.075648, Color: 13369.205750, Sat: -0.089834)\n",
      "Learning Rate: 9.85e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 95/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=3.52e+3, l1=0.0689, color=1.17e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/200] - Loss: 4027.107600 (L1: 0.075608, Color: 13423.499175, Sat: -0.089633)\n",
      "Learning Rate: 7.15e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 96/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=3.87e+3, l1=0.0722, color=1.29e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/200] - Loss: 4013.969738 (L1: 0.075614, Color: 13379.706400, Sat: -0.089728)\n",
      "Learning Rate: 4.94e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 97/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=3.94e+3, l1=0.0747, color=1.31e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/200] - Loss: 4012.046260 (L1: 0.075597, Color: 13373.294825, Sat: -0.089669)\n",
      "Learning Rate: 3.22e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 98/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=3.92e+3, l1=0.067, color=1.31e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/200] - Loss: 4019.355918 (L1: 0.075675, Color: 13397.660300, Sat: -0.090078)\n",
      "Learning Rate: 1.99e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=3.53e+3, l1=0.0653, color=1.18e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/200] - Loss: 4009.461414 (L1: 0.075589, Color: 13364.678625, Sat: -0.089661)\n",
      "Learning Rate: 1.25e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.1e+3, l1=0.0873, color=1.37e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/200] - Loss: 4005.975379 (L1: 0.075646, Color: 13353.058525, Sat: -0.089959)\n",
      "Learning Rate: 1.00e-06\n",
      "\n",
      "ðŸ’¾ Checkpoint at epoch 100\n",
      "âœ… Checkpoint saved: /kaggle/working/checkpoint_epoch_100.pth\n",
      "ðŸŽ¨ Generating visualization...\n",
      "âœ… Visualization saved: /kaggle/working/visualization_epoch_100.png\n",
      "ðŸ“Š Loss plot saved\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.01e+3, l1=0.0676, color=1.34e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/200] - Loss: 4010.433998 (L1: 0.075617, Color: 13367.920575, Sat: -0.089821)\n",
      "Learning Rate: 1.25e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 102/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=4.26e+3, l1=0.0678, color=1.42e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [102/200] - Loss: 4010.048910 (L1: 0.075588, Color: 13366.637000, Sat: -0.089671)\n",
      "Learning Rate: 1.99e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 103/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.04e+3, l1=0.0818, color=1.35e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/200] - Loss: 4008.470829 (L1: 0.075585, Color: 13361.376700, Sat: -0.089652)\n",
      "Learning Rate: 3.22e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 104/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.49it/s, loss=3.94e+3, l1=0.0788, color=1.31e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [104/200] - Loss: 4017.509472 (L1: 0.075544, Color: 13391.505475, Sat: -0.089422)\n",
      "Learning Rate: 4.94e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 105/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.5e+3, l1=0.0665, color=1.5e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/200] - Loss: 4012.167468 (L1: 0.075683, Color: 13373.698800, Sat: -0.090101)\n",
      "Learning Rate: 7.15e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 106/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.13e+3, l1=0.0799, color=1.38e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106/200] - Loss: 4011.204007 (L1: 0.075656, Color: 13370.487275, Sat: -0.089953)\n",
      "Learning Rate: 9.85e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 107/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=3.94e+3, l1=0.0704, color=1.31e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/200] - Loss: 4014.809179 (L1: 0.075590, Color: 13382.504475, Sat: -0.089591)\n",
      "Learning Rate: 1.30e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 108/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=3.52e+3, l1=0.0611, color=11742.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108/200] - Loss: 4008.635622 (L1: 0.075655, Color: 13361.925875, Sat: -0.089873)\n",
      "Learning Rate: 1.67e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 109/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.43it/s, loss=4.3e+3, l1=0.0792, color=1.43e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/200] - Loss: 4021.748891 (L1: 0.075714, Color: 13405.636825, Sat: -0.090140)\n",
      "Learning Rate: 2.08e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 110/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.43it/s, loss=4.2e+3, l1=0.0805, color=1.4e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/200] - Loss: 4007.052886 (L1: 0.075583, Color: 13356.650050, Sat: -0.089469)\n",
      "Learning Rate: 2.54e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 111/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.23e+3, l1=0.0779, color=1.41e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/200] - Loss: 4012.827166 (L1: 0.075724, Color: 13375.897675, Sat: -0.090112)\n",
      "Learning Rate: 3.05e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 112/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.44it/s, loss=3.82e+3, l1=0.0883, color=1.27e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/200] - Loss: 4015.097598 (L1: 0.075629, Color: 13383.465750, Sat: -0.089663)\n",
      "Learning Rate: 3.61e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 113/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=3.96e+3, l1=0.0752, color=1.32e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/200] - Loss: 4016.629746 (L1: 0.075630, Color: 13388.572850, Sat: -0.089539)\n",
      "Learning Rate: 4.21e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 114/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=3.66e+3, l1=0.0754, color=1.22e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [114/200] - Loss: 4021.160184 (L1: 0.075628, Color: 13403.674275, Sat: -0.089468)\n",
      "Learning Rate: 4.85e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=3.69e+3, l1=0.0617, color=1.23e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [115/200] - Loss: 4017.593752 (L1: 0.075772, Color: 13391.786100, Sat: -0.090124)\n",
      "Learning Rate: 5.54e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 116/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.07e+3, l1=0.0758, color=1.36e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/200] - Loss: 4015.795543 (L1: 0.075726, Color: 13385.792075, Sat: -0.089890)\n",
      "Learning Rate: 6.28e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 117/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.12e+3, l1=0.0818, color=1.37e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [117/200] - Loss: 4032.752481 (L1: 0.075671, Color: 13442.315250, Sat: -0.089630)\n",
      "Learning Rate: 7.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 118/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.44it/s, loss=3.7e+3, l1=0.06, color=1.23e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [118/200] - Loss: 4017.481841 (L1: 0.075725, Color: 13391.412975, Sat: -0.089687)\n",
      "Learning Rate: 7.88e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 119/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.44it/s, loss=4.68e+3, l1=0.0905, color=1.56e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [119/200] - Loss: 4022.777003 (L1: 0.075707, Color: 13409.063450, Sat: -0.089583)\n",
      "Learning Rate: 8.74e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 120/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=3.85e+3, l1=0.0707, color=12833.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/200] - Loss: 4033.692882 (L1: 0.075749, Color: 13445.449750, Sat: -0.089826)\n",
      "Learning Rate: 9.64e-05\n",
      "\n",
      "ðŸ’¾ Checkpoint at epoch 120\n",
      "âœ… Checkpoint saved: /kaggle/working/checkpoint_epoch_120.pth\n",
      "ðŸŽ¨ Generating visualization...\n",
      "âœ… Visualization saved: /kaggle/working/visualization_epoch_120.png\n",
      "ðŸ“Š Loss plot saved\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.44it/s, loss=4.42e+3, l1=0.0701, color=1.47e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/200] - Loss: 4025.843763 (L1: 0.075769, Color: 13419.285975, Sat: -0.089808)\n",
      "Learning Rate: 1.06e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 122/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=3.98e+3, l1=0.0635, color=1.33e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [122/200] - Loss: 4019.701798 (L1: 0.075805, Color: 13398.812775, Sat: -0.090007)\n",
      "Learning Rate: 1.16e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 123/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.44it/s, loss=4.23e+3, l1=0.0755, color=1.41e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [123/200] - Loss: 4032.085748 (L1: 0.075796, Color: 13440.092450, Sat: -0.089754)\n",
      "Learning Rate: 1.26e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 124/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.93e+3, l1=0.0913, color=1.64e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124/200] - Loss: 4035.103598 (L1: 0.075834, Color: 13450.151825, Sat: -0.089713)\n",
      "Learning Rate: 1.36e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 125/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=3.71e+3, l1=0.0594, color=1.24e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [125/200] - Loss: 4044.831239 (L1: 0.075845, Color: 13482.577275, Sat: -0.089874)\n",
      "Learning Rate: 1.47e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 126/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=3.8e+3, l1=0.0638, color=1.27e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [126/200] - Loss: 4042.929886 (L1: 0.075787, Color: 13476.239500, Sat: -0.089635)\n",
      "Learning Rate: 1.59e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=3.62e+3, l1=0.0651, color=1.21e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [127/200] - Loss: 4054.715265 (L1: 0.075923, Color: 13515.523825, Sat: -0.089900)\n",
      "Learning Rate: 1.70e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 128/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=3.58e+3, l1=0.0654, color=1.19e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [128/200] - Loss: 4058.076867 (L1: 0.075880, Color: 13526.729150, Sat: -0.089682)\n",
      "Learning Rate: 1.82e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 129/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.17e+3, l1=0.0796, color=1.39e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [129/200] - Loss: 4051.684683 (L1: 0.075897, Color: 13505.421875, Sat: -0.089708)\n",
      "Learning Rate: 1.94e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 130/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.51e+3, l1=0.08, color=1.5e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/200] - Loss: 4043.615469 (L1: 0.075931, Color: 13478.524375, Sat: -0.089720)\n",
      "Learning Rate: 2.07e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.44it/s, loss=4.35e+3, l1=0.0772, color=1.45e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/200] - Loss: 4057.886954 (L1: 0.075950, Color: 13526.096100, Sat: -0.090004)\n",
      "Learning Rate: 2.20e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 132/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.43it/s, loss=3.74e+3, l1=0.0676, color=1.25e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [132/200] - Loss: 4054.706045 (L1: 0.075982, Color: 13515.492875, Sat: -0.089883)\n",
      "Learning Rate: 2.33e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 133/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.42e+3, l1=0.0849, color=1.47e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [133/200] - Loss: 4062.339519 (L1: 0.075999, Color: 13540.937750, Sat: -0.089849)\n",
      "Learning Rate: 2.46e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 134/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.11e+3, l1=0.075, color=1.37e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [134/200] - Loss: 4070.375086 (L1: 0.075980, Color: 13567.722975, Sat: -0.089694)\n",
      "Learning Rate: 2.60e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 135/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.43it/s, loss=3.69e+3, l1=0.0765, color=1.23e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [135/200] - Loss: 4056.668727 (L1: 0.075991, Color: 13522.035050, Sat: -0.089768)\n",
      "Learning Rate: 2.74e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 136/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.44it/s, loss=3.42e+3, l1=0.0702, color=1.14e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [136/200] - Loss: 4061.087109 (L1: 0.075975, Color: 13536.762775, Sat: -0.089330)\n",
      "Learning Rate: 2.88e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 137/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.37e+3, l1=0.0822, color=1.46e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [137/200] - Loss: 4084.296143 (L1: 0.076037, Color: 13614.126350, Sat: -0.089787)\n",
      "Learning Rate: 3.02e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 138/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=3.4e+3, l1=0.0661, color=1.13e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [138/200] - Loss: 4075.142208 (L1: 0.076111, Color: 13583.612925, Sat: -0.089789)\n",
      "Learning Rate: 3.17e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 139/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.44it/s, loss=3.97e+3, l1=0.0608, color=13224.0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [139/200] - Loss: 4074.475413 (L1: 0.076028, Color: 13581.390525, Sat: -0.089758)\n",
      "Learning Rate: 3.31e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 140/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.44it/s, loss=5.09e+3, l1=0.0951, color=1.7e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [140/200] - Loss: 4082.048461 (L1: 0.076114, Color: 13606.633700, Sat: -0.089632)\n",
      "Learning Rate: 3.46e-04\n",
      "\n",
      "ðŸ’¾ Checkpoint at epoch 140\n",
      "âœ… Checkpoint saved: /kaggle/working/checkpoint_epoch_140.pth\n",
      "ðŸŽ¨ Generating visualization...\n",
      "âœ… Visualization saved: /kaggle/working/visualization_epoch_140.png\n",
      "ðŸ“Š Loss plot saved\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 141/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=3.9e+3, l1=0.0641, color=1.3e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [141/200] - Loss: 4102.741956 (L1: 0.076045, Color: 13675.612150, Sat: -0.089497)\n",
      "Learning Rate: 3.61e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.44it/s, loss=4.17e+3, l1=0.0771, color=13907.0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [142/200] - Loss: 4078.958530 (L1: 0.076093, Color: 13596.333925, Sat: -0.089534)\n",
      "Learning Rate: 3.76e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 143/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.37e+3, l1=0.0862, color=1.46e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [143/200] - Loss: 4076.785720 (L1: 0.076211, Color: 13589.091100, Sat: -0.089961)\n",
      "Learning Rate: 3.92e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 144/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.13e+3, l1=0.0682, color=1.38e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [144/200] - Loss: 4125.615894 (L1: 0.076230, Color: 13751.857900, Sat: -0.089418)\n",
      "Learning Rate: 4.07e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 145/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=3.73e+3, l1=0.0847, color=1.24e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [145/200] - Loss: 4115.308914 (L1: 0.076219, Color: 13717.501500, Sat: -0.089611)\n",
      "Learning Rate: 4.22e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 146/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.44it/s, loss=3.6e+3, l1=0.0638, color=1.2e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [146/200] - Loss: 4108.203580 (L1: 0.076116, Color: 13693.817175, Sat: -0.089284)\n",
      "Learning Rate: 4.38e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 147/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.43it/s, loss=4.23e+3, l1=0.069, color=1.41e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [147/200] - Loss: 4109.152171 (L1: 0.076262, Color: 13696.978950, Sat: -0.089740)\n",
      "Learning Rate: 4.53e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 148/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.45e+3, l1=0.0793, color=1.48e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [148/200] - Loss: 4119.242704 (L1: 0.076247, Color: 13730.613950, Sat: -0.089421)\n",
      "Learning Rate: 4.69e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 149/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.79e+3, l1=0.074, color=1.6e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [149/200] - Loss: 4119.315202 (L1: 0.076178, Color: 13730.855600, Sat: -0.089140)\n",
      "Learning Rate: 4.85e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 150/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.3e+3, l1=0.104, color=1.43e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [150/200] - Loss: 4121.157179 (L1: 0.076249, Color: 13736.995550, Sat: -0.089454)\n",
      "Learning Rate: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 151/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=4.51e+3, l1=0.0669, color=1.5e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [151/200] - Loss: 4117.112788 (L1: 0.076346, Color: 13723.514050, Sat: -0.089696)\n",
      "Learning Rate: 5.16e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 152/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=3.93e+3, l1=0.0793, color=1.31e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [152/200] - Loss: 4122.478481 (L1: 0.076263, Color: 13741.399625, Sat: -0.089201)\n",
      "Learning Rate: 5.32e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 153/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.26e+3, l1=0.0902, color=1.42e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [153/200] - Loss: 4103.592570 (L1: 0.076262, Color: 13678.446625, Sat: -0.089257)\n",
      "Learning Rate: 5.48e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 154/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.44it/s, loss=3.7e+3, l1=0.0655, color=1.23e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [154/200] - Loss: 4130.589548 (L1: 0.076336, Color: 13768.436250, Sat: -0.089178)\n",
      "Learning Rate: 5.63e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 155/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=3.94e+3, l1=0.0699, color=1.31e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [155/200] - Loss: 4126.612412 (L1: 0.076371, Color: 13755.179225, Sat: -0.089546)\n",
      "Learning Rate: 5.79e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 156/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.43it/s, loss=4.3e+3, l1=0.0877, color=1.43e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [156/200] - Loss: 4112.595491 (L1: 0.076353, Color: 13708.456125, Sat: -0.089374)\n",
      "Learning Rate: 5.94e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 157/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.46it/s, loss=4.61e+3, l1=0.0809, color=1.54e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [157/200] - Loss: 4179.321963 (L1: 0.076367, Color: 13930.877400, Sat: -0.089080)\n",
      "Learning Rate: 6.09e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 158/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.43it/s, loss=4.66e+3, l1=0.0746, color=1.55e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [158/200] - Loss: 4152.847584 (L1: 0.076411, Color: 13842.629700, Sat: -0.089587)\n",
      "Learning Rate: 6.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 159/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=3.89e+3, l1=0.0754, color=1.3e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [159/200] - Loss: 4151.182171 (L1: 0.076360, Color: 13837.078275, Sat: -0.089173)\n",
      "Learning Rate: 6.40e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 160/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.82e+3, l1=0.0783, color=1.61e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [160/200] - Loss: 4136.421712 (L1: 0.076494, Color: 13787.876425, Sat: -0.089400)\n",
      "Learning Rate: 6.55e-04\n",
      "\n",
      "ðŸ’¾ Checkpoint at epoch 160\n",
      "âœ… Checkpoint saved: /kaggle/working/checkpoint_epoch_160.pth\n",
      "ðŸŽ¨ Generating visualization...\n",
      "âœ… Visualization saved: /kaggle/working/visualization_epoch_160.png\n",
      "ðŸ“Š Loss plot saved\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 161/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.51it/s, loss=4.29e+3, l1=0.0772, color=1.43e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [161/200] - Loss: 4150.798930 (L1: 0.076424, Color: 13835.800725, Sat: -0.089402)\n",
      "Learning Rate: 6.70e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 162/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=4.41e+3, l1=0.0918, color=1.47e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [162/200] - Loss: 4148.089384 (L1: 0.076380, Color: 13826.768925, Sat: -0.089224)\n",
      "Learning Rate: 6.84e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 163/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.51it/s, loss=4.25e+3, l1=0.0841, color=1.42e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [163/200] - Loss: 4159.163750 (L1: 0.076549, Color: 13863.682975, Sat: -0.089285)\n",
      "Learning Rate: 6.99e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 164/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=4.23e+3, l1=0.0618, color=1.41e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [164/200] - Loss: 4162.352341 (L1: 0.076399, Color: 13874.311975, Sat: -0.089120)\n",
      "Learning Rate: 7.13e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 165/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.55it/s, loss=3.96e+3, l1=0.0784, color=1.32e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [165/200] - Loss: 4159.065125 (L1: 0.076533, Color: 13863.354225, Sat: -0.089166)\n",
      "Learning Rate: 7.27e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 166/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=4.87e+3, l1=0.107, color=1.62e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [166/200] - Loss: 4158.306363 (L1: 0.076485, Color: 13860.825100, Sat: -0.089104)\n",
      "Learning Rate: 7.41e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 167/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.54it/s, loss=4.37e+3, l1=0.0723, color=1.46e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [167/200] - Loss: 4187.331223 (L1: 0.076475, Color: 13957.574675, Sat: -0.089096)\n",
      "Learning Rate: 7.55e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 168/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.51it/s, loss=4.6e+3, l1=0.077, color=1.53e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [168/200] - Loss: 4146.968462 (L1: 0.076431, Color: 13823.032325, Sat: -0.089150)\n",
      "Learning Rate: 7.68e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 169/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.55it/s, loss=5.12e+3, l1=0.0956, color=1.71e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [169/200] - Loss: 4152.624280 (L1: 0.076465, Color: 13841.884850, Sat: -0.089117)\n",
      "Learning Rate: 7.81e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 170/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=4.39e+3, l1=0.0906, color=1.46e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [170/200] - Loss: 4146.112193 (L1: 0.076501, Color: 13820.177900, Sat: -0.089245)\n",
      "Learning Rate: 7.94e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 171/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.55it/s, loss=4.61e+3, l1=0.0809, color=1.54e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [171/200] - Loss: 4158.320112 (L1: 0.076576, Color: 13860.870700, Sat: -0.089238)\n",
      "Learning Rate: 8.07e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 172/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=4.75e+3, l1=0.093, color=1.58e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [172/200] - Loss: 4194.628810 (L1: 0.076519, Color: 13981.899625, Sat: -0.088861)\n",
      "Learning Rate: 8.19e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 173/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.54it/s, loss=3.84e+3, l1=0.0777, color=1.28e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [173/200] - Loss: 4216.496985 (L1: 0.076564, Color: 14054.793250, Sat: -0.088711)\n",
      "Learning Rate: 8.31e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 174/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.55it/s, loss=3.89e+3, l1=0.0657, color=1.3e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [174/200] - Loss: 4172.874965 (L1: 0.076550, Color: 13909.386875, Sat: -0.089111)\n",
      "Learning Rate: 8.42e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 175/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=3.39e+3, l1=0.0764, color=1.13e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [175/200] - Loss: 4192.182672 (L1: 0.076599, Color: 13973.745675, Sat: -0.088938)\n",
      "Learning Rate: 8.54e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 176/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.54it/s, loss=3.79e+3, l1=0.074, color=1.26e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [176/200] - Loss: 4186.196490 (L1: 0.076624, Color: 13953.791475, Sat: -0.088802)\n",
      "Learning Rate: 8.65e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 177/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=3.36e+3, l1=0.0641, color=1.12e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [177/200] - Loss: 4174.176789 (L1: 0.076597, Color: 13913.726000, Sat: -0.088915)\n",
      "Learning Rate: 8.75e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 178/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.55it/s, loss=4.66e+3, l1=0.106, color=1.55e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [178/200] - Loss: 4203.944121 (L1: 0.076585, Color: 14012.950500, Sat: -0.088880)\n",
      "Learning Rate: 8.85e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=3.86e+3, l1=0.0794, color=1.29e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [179/200] - Loss: 4189.124091 (L1: 0.076642, Color: 13963.549800, Sat: -0.088421)\n",
      "Learning Rate: 8.95e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 180/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.55it/s, loss=3.85e+3, l1=0.074, color=1.28e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [180/200] - Loss: 4174.893803 (L1: 0.076646, Color: 13916.115850, Sat: -0.088946)\n",
      "Learning Rate: 9.05e-04\n",
      "\n",
      "ðŸ’¾ Checkpoint at epoch 180\n",
      "âœ… Checkpoint saved: /kaggle/working/checkpoint_epoch_180.pth\n",
      "ðŸŽ¨ Generating visualization...\n",
      "âœ… Visualization saved: /kaggle/working/visualization_epoch_180.png\n",
      "ðŸ“Š Loss plot saved\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 181/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=3.82e+3, l1=0.0717, color=1.27e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [181/200] - Loss: 4159.578696 (L1: 0.076524, Color: 13865.066050, Sat: -0.089129)\n",
      "Learning Rate: 9.14e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 182/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.54it/s, loss=4.16e+3, l1=0.0773, color=1.39e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [182/200] - Loss: 4164.271422 (L1: 0.076600, Color: 13880.708325, Sat: -0.089269)\n",
      "Learning Rate: 9.22e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 183/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=3.91e+3, l1=0.0824, color=1.3e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [183/200] - Loss: 4191.901109 (L1: 0.076558, Color: 13972.807050, Sat: -0.088718)\n",
      "Learning Rate: 9.30e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 184/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.55it/s, loss=4.56e+3, l1=0.0832, color=1.52e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [184/200] - Loss: 4188.440272 (L1: 0.076596, Color: 13961.270825, Sat: -0.088789)\n",
      "Learning Rate: 9.38e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 185/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.52it/s, loss=3.77e+3, l1=0.0758, color=1.26e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [185/200] - Loss: 4193.815471 (L1: 0.076580, Color: 13979.188300, Sat: -0.088867)\n",
      "Learning Rate: 9.46e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 186/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:35<00:00,  6.53it/s, loss=4.05e+3, l1=0.092, color=1.35e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [186/200] - Loss: 4229.863434 (L1: 0.076636, Color: 14099.347725, Sat: -0.088506)\n",
      "Learning Rate: 9.52e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 187/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.50it/s, loss=3.55e+3, l1=0.0715, color=1.18e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [187/200] - Loss: 4216.787839 (L1: 0.076676, Color: 14055.762800, Sat: -0.089252)\n",
      "Learning Rate: 9.59e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 188/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.44it/s, loss=4.43e+3, l1=0.0769, color=1.48e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [188/200] - Loss: 4219.614411 (L1: 0.076624, Color: 14065.184525, Sat: -0.088671)\n",
      "Learning Rate: 9.65e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 189/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.49it/s, loss=4.52e+3, l1=0.0854, color=15064.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [189/200] - Loss: 4202.109859 (L1: 0.076619, Color: 14006.835950, Sat: -0.088617)\n",
      "Learning Rate: 9.70e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 190/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.42e+3, l1=0.0695, color=1.47e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [190/200] - Loss: 4219.991897 (L1: 0.076855, Color: 14066.442250, Sat: -0.089034)\n",
      "Learning Rate: 9.76e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 191/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.71e+3, l1=0.0936, color=1.57e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [191/200] - Loss: 4219.545479 (L1: 0.076733, Color: 14064.954575, Sat: -0.088943)\n",
      "Learning Rate: 9.80e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 192/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=4.49e+3, l1=0.0821, color=1.5e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [192/200] - Loss: 4208.721254 (L1: 0.076649, Color: 14028.874050, Sat: -0.088970)\n",
      "Learning Rate: 9.84e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 193/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.26e+3, l1=0.0811, color=1.42e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [193/200] - Loss: 4203.001733 (L1: 0.076593, Color: 14009.809225, Sat: -0.089020)\n",
      "Learning Rate: 9.88e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 194/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.48it/s, loss=4.22e+3, l1=0.0764, color=1.41e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [194/200] - Loss: 4192.824028 (L1: 0.076708, Color: 13975.883175, Sat: -0.089045)\n",
      "Learning Rate: 9.91e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 195/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:37<00:00,  6.44it/s, loss=4.04e+3, l1=0.0695, color=1.35e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [195/200] - Loss: 4214.762941 (L1: 0.076645, Color: 14049.013250, Sat: -0.089270)\n",
      "Learning Rate: 9.94e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 196/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.42e+3, l1=0.0749, color=1.47e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [196/200] - Loss: 4210.335982 (L1: 0.076632, Color: 14034.256425, Sat: -0.088716)\n",
      "Learning Rate: 9.96e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 197/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.54e+3, l1=0.0584, color=1.51e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [197/200] - Loss: 4211.664028 (L1: 0.076636, Color: 14038.683275, Sat: -0.088872)\n",
      "Learning Rate: 9.98e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 198/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.07e+3, l1=0.089, color=1.36e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [198/200] - Loss: 4221.684548 (L1: 0.076636, Color: 14072.085075, Sat: -0.088991)\n",
      "Learning Rate: 9.99e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.45it/s, loss=4.25e+3, l1=0.065, color=1.42e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [199/200] - Loss: 4204.847917 (L1: 0.076643, Color: 14015.962775, Sat: -0.088677)\n",
      "Learning Rate: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 200/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:36<00:00,  6.47it/s, loss=4.67e+3, l1=0.0746, color=1.56e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/200] - Loss: 4217.089261 (L1: 0.076751, Color: 14056.767175, Sat: -0.089092)\n",
      "Learning Rate: 1.00e-03\n",
      "\n",
      "ðŸ’¾ Checkpoint at epoch 200\n",
      "âœ… Checkpoint saved: /kaggle/working/checkpoint_epoch_200.pth\n",
      "ðŸŽ¨ Generating visualization...\n",
      "âœ… Visualization saved: /kaggle/working/visualization_epoch_200.png\n",
      "ðŸ“Š Loss plot saved\n",
      "============================================================\n",
      "Training completed successfully!\n",
      "âœ… Final model saved: /kaggle/working/final_model.pth\n",
      "ðŸŽ‰ Training completed successfully!\n",
      "ðŸ“ All checkpoints and visualizations saved to: /kaggle/working/\n"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parallel import DataParallel\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "#from cnn_transformer_colorizer_v1 import CNNTransformerColorizer \n",
    "\n",
    "# ============================================================\n",
    "# Enhanced Loss Function\n",
    "# ============================================================\n",
    "class EnhancedColorizationLoss(nn.Module):\n",
    "    def __init__(self, l1_weight=1.0, color_weight=0.3, saturation_weight=0.2):\n",
    "        super().__init__()\n",
    "        self.l1_weight = l1_weight\n",
    "        self.color_weight = color_weight\n",
    "        self.saturation_weight = saturation_weight\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        \n",
    "    def color_distribution_loss(self, pred, target):\n",
    "        # Encourage similar color distribution using histogram matching\n",
    "        pred_flat = pred.view(pred.size(0), 2, -1)\n",
    "        target_flat = target.view(target.size(0), 2, -1)\n",
    "        \n",
    "        # Compute histogram for each channel\n",
    "        hist_loss = 0\n",
    "        for c in range(2):\n",
    "            pred_hist = torch.histc(pred_flat[:, c], bins=64, min=-1, max=1)\n",
    "            target_hist = torch.histc(target_flat[:, c], bins=64, min=-1, max=1)\n",
    "            hist_loss += F.l1_loss(pred_hist, target_hist)\n",
    "        \n",
    "        return hist_loss / 2\n",
    "    \n",
    "    def saturation_encouragement(self, pred):\n",
    "        # Encourage higher saturation (penalize gray outputs)\n",
    "        # Compute saturation as magnitude in AB space\n",
    "        saturation = torch.sqrt(pred[:, 0:1]**2 + pred[:, 1:2]**2)\n",
    "        # We want to maximize saturation, so we minimize negative saturation\n",
    "        return -torch.mean(saturation)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        l1_loss = self.l1_loss(pred, target)\n",
    "        color_loss = self.color_distribution_loss(pred, target)\n",
    "        sat_loss = self.saturation_encouragement(pred)\n",
    "        \n",
    "        total_loss = (self.l1_weight * l1_loss + \n",
    "                     self.color_weight * color_loss + \n",
    "                     self.saturation_weight * sat_loss)\n",
    "        \n",
    "        return total_loss, {'l1': l1_loss.item(), 'color': color_loss.item(), 'saturation': sat_loss.item()}\n",
    "\n",
    "# ============================================================\n",
    "# Dataset\n",
    "# ============================================================\n",
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, data_dir, split=\"train\", max_samples=100000):\n",
    "        data_dir = Path(data_dir)\n",
    "\n",
    "        # Correct structure:\n",
    "        # processed/grayscale/train/*.jpg\n",
    "        # processed/color/train/*.npy\n",
    "        g_root = data_dir / \"grayscale\" / split\n",
    "        c_root = data_dir / \"color\" / split\n",
    "\n",
    "        if not g_root.exists() or not c_root.exists():\n",
    "            raise RuntimeError(\n",
    "                f\"Expected folders:\\n{g_root}\\n{c_root}\\nbut they were not found.\"\n",
    "            )\n",
    "\n",
    "        print(f\"ðŸ“ Loading {split.upper()} split\")\n",
    "        print(f\"Searching for grayscale images in: {g_root}\")\n",
    "\n",
    "        # Load grayscale files\n",
    "        self.gray_files = []\n",
    "        for root, dirs, files in os.walk(g_root):\n",
    "            jpg_files = [f for f in files if f.lower().endswith(\".jpg\")]\n",
    "            for f in jpg_files:\n",
    "                self.gray_files.append(Path(root) / f)\n",
    "                if len(self.gray_files) >= max_samples:\n",
    "                    break\n",
    "            if len(self.gray_files) >= max_samples:\n",
    "                break\n",
    "\n",
    "        print(f\"ðŸ“ Total grayscale images found: {len(self.gray_files)}\")\n",
    "\n",
    "        self.gray_files = sorted(self.gray_files)\n",
    "        self.gray_root = g_root\n",
    "        self.color_root = c_root\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gray_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gray_path = self.gray_files[idx]\n",
    "\n",
    "        # relative path inside grayscale/train\n",
    "        rel = gray_path.relative_to(self.gray_root)\n",
    "\n",
    "        # corresponding color/train/*.npy\n",
    "        color_path = (self.color_root / rel).with_suffix(\".npy\")\n",
    "\n",
    "        # Load grayscale\n",
    "        L = np.array(Image.open(gray_path)).astype(\"float32\")\n",
    "        L = (L / 127.5) - 1.0\n",
    "\n",
    "        # Load AB\n",
    "        AB = np.load(color_path).astype(\"float32\")\n",
    "\n",
    "        L = torch.tensor(L).unsqueeze(0)\n",
    "        AB = torch.tensor(AB).permute(2, 0, 1)\n",
    "\n",
    "        return L, AB\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Enhanced Training Function with Checkpoints and Visualizations\n",
    "# ============================================================\n",
    "def train_model_multi_gpu(model, train_loader, criterion, optimizer, scheduler, device, epochs=5, save_dir=\"/kaggle/working\"):\n",
    "    \"\"\"\n",
    "    Enhanced training function with periodic checkpoints and visualizations\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # Create save directory\n",
    "    save_path = Path(save_dir)\n",
    "    save_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Store loss history\n",
    "    loss_history = {\n",
    "        'total': [], 'l1': [], 'color': [], 'saturation': [], 'lr': []\n",
    "    }\n",
    "    \n",
    "    # GPU monitoring function\n",
    "    def print_gpu_usage():\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"GPU Memory Usage:\")\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                alloc = torch.cuda.memory_allocated(i) / 1024**3\n",
    "                cached = torch.cuda.memory_reserved(i) / 1024**3\n",
    "                print(f\"  GPU {i}: {alloc:.2f}GB / {cached:.2f}GB\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        total_l1 = 0.0\n",
    "        total_color = 0.0\n",
    "        total_sat = 0.0\n",
    "        \n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        for i, (L, AB) in pbar:\n",
    "            L, AB = L.to(device, non_blocking=True), AB.to(device, non_blocking=True)\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            output = model(L)\n",
    "\n",
    "            # --- Sanity check (only for first batch of first epoch)\n",
    "            if epoch == 0 and i == 0:\n",
    "                print(\"\\n=== Sanity check for shapes ===\")\n",
    "                print(f\"Input L shape: {L.shape}\")\n",
    "                print(f\"Output (predicted AB) shape: {output.shape}\")\n",
    "                print(f\"Target AB shape: {AB.shape}\")\n",
    "                print(f\"Output min/max: {output.min().item():.4f} / {output.max().item():.4f}\")\n",
    "                print(f\"Target min/max: {AB.min().item():.4f} / {AB.max().item():.4f}\")\n",
    "\n",
    "            # --- Resize for safety on every batch\n",
    "            if output.shape != AB.shape:\n",
    "                output = torch.nn.functional.interpolate(output, size=(AB.shape[2], AB.shape[3]), mode='bilinear', align_corners=False)\n",
    "\n",
    "            # Compute enhanced loss\n",
    "            loss, loss_components = criterion(output, AB)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_l1 += loss_components['l1']\n",
    "            total_color += loss_components['color']\n",
    "            total_sat += loss_components['saturation']\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': loss.item(), \n",
    "                'l1': loss_components['l1'],\n",
    "                'color': loss_components['color']\n",
    "            })\n",
    "            \n",
    "            # Print GPU usage first batch of first epoch\n",
    "            if epoch == 0 and i == 0:\n",
    "                print_gpu_usage()\n",
    "\n",
    "        # Step the scheduler\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "        else:\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_l1 = total_l1 / len(train_loader)\n",
    "        avg_color = total_color / len(train_loader)\n",
    "        avg_sat = total_sat / len(train_loader)\n",
    "        \n",
    "        # Store loss history\n",
    "        loss_history['total'].append(avg_loss)\n",
    "        loss_history['l1'].append(avg_l1)\n",
    "        loss_history['color'].append(avg_color)\n",
    "        loss_history['saturation'].append(avg_sat)\n",
    "        loss_history['lr'].append(current_lr)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.6f} (L1: {avg_l1:.6f}, Color: {avg_color:.6f}, Sat: {avg_sat:.6f})\")\n",
    "        print(f\"Learning Rate: {current_lr:.2e}\")\n",
    "\n",
    "        # ============================================================\n",
    "        # Save checkpoint and generate visualization every 20 epochs\n",
    "        # ============================================================\n",
    "        if (epoch + 1) % 20 == 0 or epoch == 0 or epoch == epochs - 1:\n",
    "            print(f\"\\nðŸ’¾ Checkpoint at epoch {epoch+1}\")\n",
    "            \n",
    "            # Handle DataParallel wrapping for saving\n",
    "            if hasattr(model, 'module'):\n",
    "                model_to_save = model.module\n",
    "            else:\n",
    "                model_to_save = model\n",
    "            \n",
    "            # Save model checkpoint\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model_to_save.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                'loss_history': loss_history,\n",
    "                'total_loss': avg_loss,\n",
    "            }\n",
    "            \n",
    "            checkpoint_path = save_path / f\"checkpoint_epoch_{epoch+1:03d}.pth\"\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            print(f\"âœ… Checkpoint saved: {checkpoint_path}\")\n",
    "            \n",
    "            # Generate and save visualization\n",
    "            print(\"ðŸŽ¨ Generating visualization...\")\n",
    "            try:\n",
    "                visualization_path = save_path / f\"visualization_epoch_{epoch+1:03d}.png\"\n",
    "                generate_visualization(model_to_save, train_loader.dataset, device, \n",
    "                                     save_path=visualization_path, epoch=epoch+1)\n",
    "                print(f\"âœ… Visualization saved: {visualization_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Failed to generate visualization: {e}\")\n",
    "            \n",
    "            # Plot loss history\n",
    "            plot_loss_history(loss_history, save_path / f\"loss_plot_epoch_{epoch+1:03d}.png\")\n",
    "            print(f\"ðŸ“Š Loss plot saved\")\n",
    "            \n",
    "            print(\"=\" * 60)\n",
    "\n",
    "    print(\"Training completed successfully!\")\n",
    "    \n",
    "    # Save final model\n",
    "    if hasattr(model, 'module'):\n",
    "        model_to_save = model.module\n",
    "    else:\n",
    "        model_to_save = model\n",
    "        \n",
    "    final_model_path = save_path / \"final_model.pth\"\n",
    "    torch.save(model_to_save.state_dict(), final_model_path)\n",
    "    print(f\"âœ… Final model saved: {final_model_path}\")\n",
    "    \n",
    "    return model, loss_history\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Enhanced Visualization with Saving Capability\n",
    "# ============================================================\n",
    "def generate_visualization(model, dataset, device, num_samples=3, saturation_boost=1.3, \n",
    "                         save_path=None, epoch=None):\n",
    "    \"\"\"\n",
    "    Visualize model predictions and optionally save to file.\n",
    "    All values are in [-1, 1] range.\n",
    "    \"\"\"\n",
    "    from skimage import color\n",
    "    \n",
    "    model.eval()\n",
    "    idxs = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 4 * num_samples))\n",
    "    \n",
    "    if epoch is not None:\n",
    "        plt.suptitle(f\"Epoch {epoch} - Model Predictions\", fontsize=16, y=0.95)\n",
    "    \n",
    "    for i, idx in enumerate(idxs):\n",
    "        L, AB = dataset[idx]\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            pred_AB = model(L.unsqueeze(0).to(device)).cpu().squeeze(0)\n",
    "        \n",
    "        # Apply saturation boost to predictions\n",
    "        pred_AB_boosted = pred_AB * saturation_boost\n",
    "        pred_AB_boosted = torch.clamp(pred_AB_boosted, -1.0, 1.0)\n",
    "        \n",
    "        # Convert from tensors to numpy\n",
    "        L_np = L.squeeze().numpy()  # [-1, 1]\n",
    "        pred_AB_np = pred_AB.permute(1, 2, 0).numpy()  # [-1, 1]\n",
    "        pred_AB_boosted_np = pred_AB_boosted.permute(1, 2, 0).numpy()  # [-1, 1]\n",
    "        AB_gt_np = AB.permute(1, 2, 0).numpy()  # [-1, 1]\n",
    "        \n",
    "        # Convert back to CIELAB range\n",
    "        L_lab = (L_np + 1.0) * 50.0  # [-1, 1] -> [0, 100]\n",
    "        pred_AB_lab = pred_AB_np * 110.0  # [-1, 1] -> [-110, 110]\n",
    "        pred_AB_boosted_lab = pred_AB_boosted_np * 110.0  # [-1, 1] -> [-110, 110]\n",
    "        AB_gt_lab = AB_gt_np * 110.0  # [-1, 1] -> [-110, 110]\n",
    "        \n",
    "        # Reconstruct LAB images\n",
    "        pred_lab = np.zeros((L_lab.shape[0], L_lab.shape[1], 3))\n",
    "        pred_lab[:, :, 0] = L_lab\n",
    "        pred_lab[:, :, 1:] = pred_AB_lab\n",
    "        \n",
    "        pred_boosted_lab = np.zeros_like(pred_lab)\n",
    "        pred_boosted_lab[:, :, 0] = L_lab\n",
    "        pred_boosted_lab[:, :, 1:] = pred_AB_boosted_lab\n",
    "        \n",
    "        gt_lab = np.zeros_like(pred_lab)\n",
    "        gt_lab[:, :, 0] = L_lab\n",
    "        gt_lab[:, :, 1:] = AB_gt_lab\n",
    "        \n",
    "        # Convert LAB to RGB using skimage\n",
    "        pred_rgb = color.lab2rgb(pred_lab)\n",
    "        pred_boosted_rgb = color.lab2rgb(pred_boosted_lab)\n",
    "        gt_rgb = color.lab2rgb(gt_lab)\n",
    "        \n",
    "        # Plot\n",
    "        plt.subplot(num_samples, 4, 4 * i + 1)\n",
    "        plt.imshow(L_np, cmap=\"gray\", vmin=-1, vmax=1)\n",
    "        plt.title(\"Input L\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 4, 4 * i + 2)\n",
    "        plt.imshow(np.clip(pred_rgb, 0, 1))\n",
    "        plt.title(\"Predicted Color\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(num_samples, 4, 4 * i + 3)\n",
    "        plt.imshow(np.clip(pred_boosted_rgb, 0, 1))\n",
    "        plt.title(f\"Boosted (x{saturation_boost})\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 4, 4 * i + 4)\n",
    "        plt.imshow(np.clip(gt_rgb, 0, 1))\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close(fig)  # Close the figure to free memory\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# NEW: Loss History Plotting Function\n",
    "# ============================================================\n",
    "def plot_loss_history(loss_history, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot and save loss history\n",
    "    \"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    epochs = range(1, len(loss_history['total']) + 1)\n",
    "    \n",
    "    # Total loss\n",
    "    ax1.plot(epochs, loss_history['total'])\n",
    "    ax1.set_title('Total Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # L1 loss\n",
    "    ax2.plot(epochs, loss_history['l1'])\n",
    "    ax2.set_title('L1 Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('L1 Loss')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Color loss\n",
    "    ax3.plot(epochs, loss_history['color'])\n",
    "    ax3.set_title('Color Distribution Loss')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Color Loss')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate\n",
    "    ax4.plot(epochs, loss_history['lr'])\n",
    "    ax4.set_title('Learning Rate')\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('Learning Rate')\n",
    "    ax4.set_yscale('log')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Auto-detect Dataset Path (unchanged)\n",
    "# ============================================================\n",
    "def find_dataset_path():\n",
    "    \"\"\"Automatically find the dataset path in Kaggle\"\"\"\n",
    "    input_dir = Path(\"/kaggle/input/100k-data\")\n",
    "    \n",
    "    if not input_dir.exists():\n",
    "        print(\"/kaggle/input directory not found\")\n",
    "        return None\n",
    "    \n",
    "    available_datasets = [d for d in input_dir.iterdir() if d.is_dir()]\n",
    "    print(f\"Available datasets: {[d.name for d in available_datasets]}\")\n",
    "    \n",
    "    # Look for processed data\n",
    "    for dataset in available_datasets:\n",
    "        potential_path = dataset / \"processed\"\n",
    "        if potential_path.exists():\n",
    "            print(f\"Found processed data at: {potential_path}\")\n",
    "            return str(potential_path)\n",
    "    \n",
    "    # Look for train/grayscale structure directly\n",
    "    for dataset in available_datasets:\n",
    "        potential_train = dataset / \"train\" / \"grayscale\" # change \"val\" back to \"train\", mismatched  folder names\n",
    "        if potential_train.exists():\n",
    "            print(f\"Found data at: {dataset}\")\n",
    "            return str(dataset)\n",
    "    \n",
    "    # Use the first dataset as fallback\n",
    "    if available_datasets:\n",
    "        fallback = available_datasets[0]\n",
    "        print(f\"Using fallback dataset: {fallback}\")\n",
    "        return str(fallback)\n",
    "    \n",
    "    print(\"No datasets found\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Enhanced Main Function with Multi-GPU Support\n",
    "# ============================================================\n",
    "def main():\n",
    "    # GPU configuration\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Found {num_gpus} GPU(s)\")\n",
    "    \n",
    "    for i in range(num_gpus):\n",
    "        gpu_props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"  - GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"    Memory: {gpu_props.total_memory / 1024**3:.1f} GB\")\n",
    "    \n",
    "    # Use all available GPUs\n",
    "    if num_gpus > 1:\n",
    "        device = torch.device(\"cuda:0\")  # Use first GPU as main\n",
    "        print(f\"Using {num_gpus} GPUs with DataParallel\")\n",
    "        \n",
    "        # Model with DataParallel\n",
    "        model = CNNTransformerColorizer()\n",
    "        model = DataParallel(model)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Larger batch size for multiple GPUs\n",
    "        batch_size = 8 * num_gpus\n",
    "        \n",
    "    else:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = CNNTransformerColorizer().to(device)\n",
    "        batch_size = 8\n",
    "        print(f\"Using device: {device}\")\n",
    "\n",
    "    # Auto-detect dataset path for Kaggle\n",
    "    data_dir = find_dataset_path()\n",
    "    if data_dir is None:\n",
    "        print(\"Could not find dataset. Please check your Kaggle dataset.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Using data directory: {data_dir}\")\n",
    "    \n",
    "    try:\n",
    "        train_dataset = ColorizationDataset(data_dir, split=\"train\", max_samples=10000)\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        print(f\"Training with {len(train_dataset)} images\")\n",
    "        print(f\"Batch size: {batch_size} (adjusted for {num_gpus} GPU(s))\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        print(\"Available directories:\")\n",
    "        for root, dirs, files in os.walk(data_dir):\n",
    "            level = root.replace(str(data_dir), '').count(os.sep)\n",
    "            indent = ' ' * 2 * level\n",
    "            print(f'{indent}{os.path.basename(root)}/')\n",
    "            subindent = ' ' * 2 * (level + 1)\n",
    "            for file in files[:5]:\n",
    "                print(f'{subindent}{file}')\n",
    "            if len(files) > 5:\n",
    "                print(f'{subindent}... and {len(files) - 5} more files')\n",
    "        return\n",
    "\n",
    "    # Enhanced loss function and optimizer\n",
    "    criterion = EnhancedColorizationLoss(l1_weight=1.0, color_weight=0.3, saturation_weight=0.2)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)\n",
    "\n",
    "    print(\"Starting training with enhanced colorization...\")\n",
    "    print(\"Checkpoints and visualizations will be saved every 20 epochs\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Train with checkpointing and visualization\n",
    "    model, loss_history = train_model_multi_gpu(\n",
    "        model, train_loader, criterion, optimizer, scheduler, device, \n",
    "        epochs=200, save_dir=\"/kaggle/working\"\n",
    "    )\n",
    "\n",
    "    print(\"ðŸŽ‰ Training completed successfully!\")\n",
    "    print(f\"ðŸ“ All checkpoints and visualizations saved to: /kaggle/working/\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "186544ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T10:52:21.301592Z",
     "iopub.status.busy": "2025-11-22T10:52:21.300650Z",
     "iopub.status.idle": "2025-11-22T10:52:21.306695Z",
     "shell.execute_reply": "2025-11-22T10:52:21.306047Z"
    },
    "papermill": {
     "duration": 11.08386,
     "end_time": "2025-11-22T10:52:21.307845",
     "exception": false,
     "start_time": "2025-11-22T10:52:10.223985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import os\\nimport shutil\\n\\nfolder_path = '/kaggle/working'\\nfor filename in os.listdir(folder_path):\\n    file_path = os.path.join(folder_path, filename)\\n    try:\\n        if os.path.isfile(file_path) or os.path.islink(file_path):\\n            os.unlink(file_path)\\n        elif os.path.isdir(file_path):\\n            shutil.rmtree(file_path)\\n    except Exception as e:\\n        print(f'Failed to delete {file_path}. Reason: {e}')\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import os\n",
    "import shutil\n",
    "\n",
    "folder_path = '/kaggle/working'\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print(f'Failed to delete {file_path}. Reason: {e}')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd2e4c",
   "metadata": {
    "papermill": {
     "duration": 11.190232,
     "end_time": "2025-11-22T10:52:43.661028",
     "exception": false,
     "start_time": "2025-11-22T10:52:32.470796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8782001,
     "sourceId": 13793988,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8792130,
     "sourceId": 13807761,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19497.404425,
   "end_time": "2025-11-22T10:52:58.018859",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-22T05:28:00.614434",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
