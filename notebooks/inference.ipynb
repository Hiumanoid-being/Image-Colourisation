{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76490e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "\tbase_dir = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "\tbase_dir = Path.cwd()\n",
    "\n",
    "# If the notebook sits in a 'notebooks' folder, assume the repo root is its parent\n",
    "repo_root = base_dir.parent if base_dir.name == \"notebooks\" else base_dir\n",
    "\n",
    "sys.path.insert(0, str(repo_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d19b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "from CNN_Transformer_Model import CNNTransformerColourizer\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f60730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to trained model checkpoint\n",
    "MODEL_PATH = r\"C:\\Users\\ethan\\Github Repositories\\Image Colourisation\\models\\final.pth\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNTransformerColourizer().to(device)\n",
    "\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "if isinstance(checkpoint, dict) and \"model_state_dict\" in checkpoint:\n",
    "\tmodel.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "else:\n",
    "\tmodel.load_state_dict(checkpoint)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616271c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to input image (grayscale or RGB)\n",
    "IMAGE_PATH = r\"C:\\Users\\ethan\\Github Repositories\\Image Colourisation\\tests\\sample_9.jpg\"\n",
    "\n",
    "# Load image\n",
    "img = Image.open(IMAGE_PATH)\n",
    "\n",
    "# Convert to grayscale if RGB\n",
    "if img.mode == 'RGB':\n",
    "\timg = img.convert('L')\n",
    "\n",
    "# Convert to numpy and normalize to [-1, 1]\n",
    "L = np.array(img).astype(\"float32\")\n",
    "L = (L / 128) - 1.0\n",
    "\n",
    "# Add batch dimension: [H, W] -> [1, H, W]\n",
    "L = torch.tensor(L).unsqueeze(0)\n",
    "\n",
    "print(\"Input image shape:\", L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a85635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction\n",
    "# ensure input is on the same device as the model\n",
    "L_tensor = L.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_AB = model(L_tensor)\n",
    "\n",
    "# Apply saturation boost (in normalized tanh [-1,1] space) and clamp\n",
    "SATURATION_BOOST = 1.2 \n",
    "pred_AB_boosted = torch.clamp(pred_AB * SATURATION_BOOST, -1.0, 1.0)\n",
    "\n",
    "# Convert to numpy and reshape: (2, H, W) -> (H, W, 2)\n",
    "L_np = L_tensor.squeeze().cpu().numpy()\n",
    "pred_AB_np = np.transpose(pred_AB.squeeze().cpu().numpy(), (1, 2, 0))\n",
    "pred_AB_boosted_np = np.transpose(pred_AB_boosted.squeeze().cpu().numpy(), (1, 2, 0))\n",
    "\n",
    "# Convert back to CIELAB ranges\n",
    "# L in [-1,1] -> normalize to [0,100]\n",
    "L_lab = ((L_np + 1.0) / 2.0) * 100.0\n",
    "\n",
    "# AB predicted in [-1,1] -> approximate a/b scale (use same scale for boosted)\n",
    "AB_SCALE = 128.0\n",
    "pred_AB_lab = pred_AB_np * AB_SCALE\n",
    "pred_AB_boosted_lab = pred_AB_boosted_np * AB_SCALE\n",
    "\n",
    "# Clip AB to reasonable CIELAB-like range to avoid extreme values\n",
    "pred_AB_lab = np.clip(pred_AB_lab, -127.0, 127.0)\n",
    "pred_AB_boosted_lab = np.clip(pred_AB_boosted_lab, -127.0, 127.0)\n",
    "\n",
    "# Reconstruct LAB images (use float dtype)\n",
    "lab_out = np.empty((L_lab.shape[0], L_lab.shape[1], 3), dtype=np.float64)\n",
    "lab_out[:, :, 0] = L_lab\n",
    "lab_out[:, :, 1:] = pred_AB_lab\n",
    "\n",
    "lab_boosted = np.empty_like(lab_out)\n",
    "lab_boosted[:, :, 0] = L_lab\n",
    "lab_boosted[:, :, 1:] = pred_AB_boosted_lab\n",
    "\n",
    "# Convert LAB â†’ RGB, clamp to [0,1] then convert to uint8 safely\n",
    "rgb_out_f = color.lab2rgb(lab_out)\n",
    "rgb_out_f = np.clip(rgb_out_f, 0.0, 1.0)\n",
    "rgb_out = (rgb_out_f * 255.0).round().astype(np.uint8)\n",
    "\n",
    "rgb_boosted_f = color.lab2rgb(lab_boosted)\n",
    "rgb_boosted_f = np.clip(rgb_boosted_f, 0.0, 1.0)\n",
    "rgb_boosted = (rgb_boosted_f * 255.0).round().astype(np.uint8)\n",
    "\n",
    "print(\"Colorized output shape:\", rgb_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032162c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing: boost saturation and save boosted result\n",
    "from PIL import ImageEnhance, Image\n",
    "\n",
    "# Factor >1 increases saturation (1.0 = original)\n",
    "SATURATION_FACTOR = 1\n",
    "\n",
    "# Convert colorized numpy array to PIL Image and boost saturation\n",
    "img_colorized = Image.fromarray(rgb_out)\n",
    "enhancer = ImageEnhance.Color(img_colorized)\n",
    "img_boosted = enhancer.enhance(SATURATION_FACTOR)\n",
    "\n",
    "# Back to numpy for further processing/display\n",
    "rgb_boosted = np.array(img_boosted)\n",
    "\n",
    "# Save boosted image to repo-level results folder\n",
    "output_path = repo_root / \"results\" / \"colorized_boosted.jpg\"\n",
    "Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "img_boosted.save(output_path)\n",
    "print(f\"Boosted saturation by {SATURATION_FACTOR} and saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Grayscale Input\")\n",
    "plt.imshow(img_np)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Colourised Output\")\n",
    "plt.imshow(rgb_out)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Boosted Saturation\")\n",
    "plt.imshow(rgb_boosted)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31424c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Gradio app...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo\n",
    "import subprocess\n",
    "import webbrowser\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "try:\n",
    "\tbase_dir = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "\tbase_dir = Path.cwd()\n",
    "repo_root = base_dir.parent if base_dir.name == \"notebooks\" else base_dir\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "# Run the Gradio app\n",
    "print(\"Starting Gradio app...\")\n",
    "process = subprocess.Popen([\n",
    "    sys.executable, \n",
    "    str(repo_root / \"src\" / \"gradio_app.py\")\n",
    "])\n",
    "\n",
    "# wait...\n",
    "time.sleep(10)\n",
    "\n",
    "# Open in browser\n",
    "webbrowser.open(\"http://localhost:7860\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
